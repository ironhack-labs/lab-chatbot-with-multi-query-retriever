{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering with LangChain, OpenAI, and MultiQuery Retriever\n",
    "\n",
    "This interactive workbook demonstrates example of Elasticsearch's [MultiQuery Retriever](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html) to generate similar queries for a given user input and apply all queries to retrieve a larger set of relevant documents from a vectorstore.\n",
    "\n",
    "Before we begin, we first split the fictional workplace documents into passages with `langchain` and uses OpenAI to transform these passages into embeddings and then store these into Elasticsearch.\n",
    "\n",
    "We will then ask a question, generate similar questions using langchain and OpenAI, retrieve relevant passages from the vector store, and use langchain and OpenAI again to provide a summary for the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install -qU jq lark langchain langchain-elasticsearch langchain_openai tiktoken\n",
    "\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Elasticsearch\n",
    "\n",
    "ℹ️ We're using an Elastic Cloud deployment of Elasticsearch for this notebook. If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial. \n",
    "\n",
    "We'll use the **Cloud ID** to identify our deployment, because we are using Elastic Cloud deployment. To find the Cloud ID for your deployment, go to https://cloud.elastic.co/deployments and select your deployment.\n",
    "\n",
    "We will use [ElasticsearchStore](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html) to connect to our elastic cloud deployment, This would help create and index data easily.  We would also send list of documents that we created in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "ELASTIC_CLOUD_ID = os.getenv('ELASTIC_CLOUD_ID')\n",
    "ELASTIC_API_KEY = os.getenv('ELASTIC_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "\n",
    "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
    "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
    "\n",
    "# https://platform.openai.com/api-keys\n",
    "OPENAI_API_KEY = getpass(\"OpenAI API key: \") \"\"\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "vectorstore = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name='chatbot_index', #give it a meaningful name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Data into Elasticsearch\n",
    "Let's download the sample dataset and deserialize the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/example-apps/chatbot-rag-app/data/data.json\"\n",
    "\n",
    "response = urlopen(url)\n",
    "data = json.load(response)\n",
    "\n",
    "with open(\"temp.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Documents into Passages\n",
    "\n",
    "We’ll chunk documents into passages in order to improve the retrieval specificity and to ensure that we can provide multiple passages within the context window of the final question answering prompt.\n",
    "\n",
    "Here we are chunking documents into 800 token passages with an overlap of 400 tokens.\n",
    "\n",
    "Here we are using a simple splitter but Langchain offers more advanced splitters to reduce the chance of context being lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\\n    chunk_size=800, chunk_overlap=400 #define chunk size and chunk overlap\\n)\\ndocs = loader.load_and_split(text_splitter=text_splitter) '"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#Populate the metadata dictionary with keys name, summary, url, category, and updated_at.\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    # Check for required fields and populate metadata\n",
    "    if all(field in record for field in [\"name\", \"summary\", \"url\", \"category\", \"updated_at\"]):\n",
    "        metadata[\"name\"] = record.get(\"name\")\n",
    "        metadata[\"summary\"] = record.get(\"summary\")\n",
    "        metadata[\"url\"] = record.get(\"url\")\n",
    "        metadata[\"category\"] = record.get(\"category\")\n",
    "        metadata[\"updated_at\"] = record.get(\"updated_at\")\n",
    "        return metadata\n",
    "    else:\n",
    "        # If any required field is missing, return None\n",
    "        print(f\"Skipping document with missing metadata: {record}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# For more loaders https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "# And 3rd party loaders https://python.langchain.com/docs/modules/data_connection/document_loaders/#third-party-loaders\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=\"temp.json\",\n",
    "    jq_schema=\".[]\",\n",
    "    content_key=\"content\",\n",
    "    metadata_func=metadata_func,\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=800, chunk_overlap=400 #define chunk size and chunk overlap\n",
    ")\n",
    "docs = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 1, 'name': 'Work From Home Policy', 'summary': 'This policy outlines the guidelines for full-time remote work, including eligibility, equipment and resources, workspace requirements, communication expectations, performance expectations, time tracking and overtime, confidentiality and data security, health and well-being, and policy reviews and updates. Employees are encouraged to direct any questions or concerns', 'url': './sharepoint/Work from home policy.txt', 'category': 'teams', 'updated_at': '2020-03-01'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 2, 'name': 'April Work From Home Update', 'summary': 'Starting May 2022, employees will need to work two days a week in the office. Coordinate with your supervisor and HR department for these days while following safety protocols.', 'url': './sharepoint/April work from home update.txt', 'category': 'teams', 'updated_at': '2022-04-29'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 3, 'name': 'Wfh Policy Update May 2023', 'summary': 'Starting May 1, 2023, our hybrid work policy will require employees to work from the office three days a week and two days remotely.', 'url': './sharepoint/WFH policy update May 2023.txt', 'category': 'teams', 'updated_at': '2023-05-01'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 4, 'name': 'Fy2024 Company Sales Strategy', 'summary': \"This sales strategy document outlines objectives, focus areas, and action plans for our tech company's sales operations in fiscal year 2024. Our primary goal is to increase revenue, expand market share, and strengthen customer relationships in our target markets. Focus areas include targeting new markets, segmenting customers, enhancing\", 'url': './sharepoint/FY2024 Company Sales Strategy.txt', 'category': 'teams', 'updated_at': '2023-04-15'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 5, 'name': 'Company Vacation Policy', 'summary': ': This policy outlines the guidelines and procedures for requesting and taking time off from work for personal and leisure purposes. Full-time employees accrue vacation time at a rate of [X hours] per month, equivalent to [Y days] per year. Vacation requests must be submitted to supervisors at least', 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/ES6rw9bKZxVBobG1WUoJpikBF9Bhx1pw_GvJWbsg-Z_HNA?e=faSHVt', 'category': 'sharepoint', 'updated_at': '2018-04-16'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 6, 'name': 'Swe Career Matrix', 'summary': '\\nThis career leveling matrix provides a framework for understanding the various roles and responsibilities of Software Engineers, as well as the skills and experience required for each level. It is intended to support employee development, facilitate performance evaluations, and provide a clear career progression path.', 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/EVYuEyRhHh5Aqc3a39sqbGcBkqKIHRWtJBjjUjNs6snpMg?e=nv1mf4', 'category': 'sharepoint', 'updated_at': 'No update date'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 7, 'name': 'Sales Engineering Collaboration', 'summary': \": This guide provides an overview of how engineers can effectively collaborate with the sales team to ensure the success of a tech company. It includes understanding the sales team's role, communicating and collaborating on projects, engaging customers, and providing mutual respect and support.\", 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/EW21-KJnfHBFoRiF49_uJMcBfHyPKimuPOFsCcJypQWaBQ?e=mGdIqe', 'category': 'sharepoint', 'updated_at': 'No update date'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 8, 'name': 'Intellectual Property Policy', 'summary': \"This Intellectual Property Policy outlines guidelines and procedures for the ownership, protection, and utilization of intellectual property generated by employees during their employment. It establishes the company's ownership of work generated on company time, while recognizing employee ownership of work generated outside of company time without the use of company resources. The policy\", 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/EWz3cYEVdzBNsiHsYbKhms4BVYGhravyrUw3T3lzxL4pTg?e=mPIgbO', 'category': 'sharepoint', 'updated_at': 'No update date'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 9, 'name': 'Code Of Conduct', 'summary': 'This code of conduct outlines the principles and values that all employees are expected to uphold in their interactions with colleagues, customers, partners, and other stakeholders. It sets out core values such as integrity, respect, accountability, collaboration and excellence. Employees must comply with all applicable laws, regulations, and organizational', 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/ER3xmeKaZ_pAqPeJWyyNR0QBg6QmoWIGPhwfEyCABWHrPA?e=cvzrgV', 'category': 'sharepoint', 'updated_at': 'No update date'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 10, 'name': 'Office Pet Policy', 'summary': 'This policy outlines the guidelines and procedures for bringing pets into the workplace. It covers approval process, pet behavior and supervision, allergies and phobias, cleanliness and hygiene, liability, restricted areas, and policy review. Employees must obtain prior approval from their supervisor and the HR department before bringing their', 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/ETf-69wBeaZJpAn3CY7ExRABQWvav-p24VOnB6C0A4l2pQ?e=X72WuK', 'category': 'sharepoint', 'updated_at': 'No update date'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 11, 'name': 'Performance Management Policy', 'summary': 'This Performance Management Policy outlines a consistent and transparent process for evaluating, recognizing, and rewarding employees. It includes goal setting, ongoing feedback, performance evaluations, ratings, promotions, and rewards. The policy applies to all employees and encourages open communication and professional growth.', 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/ERsxt9p1uehJqeJu4JlxkakBavbKwcldrYv_hpv3xHikAw?e=pf5R2C', 'category': 'sharepoint', 'updated_at': 'No update date'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 12, 'name': 'Sales Organization Overview', 'summary': '\\nOur sales organization is divided into four regions: The Americas, Europe, Asia-Pacific, and Middle East & Africa. Each region is led by an Area Vice-President and consists of dedicated account managers, sales representatives, and support staff. They collaborate with other departments to ensure the delivery of high', 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/EYsr1eqgn9hMslMJFLR-k54BBX-O3iC26bK7xNEBtYIBkg?e=xeAjiT', 'category': 'sharepoint', 'updated_at': 'No update date'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 13, 'name': 'Compensation Framework For It Teams', 'summary': 'This document outlines a compensation framework for IT teams. It includes job levels, compensation bands, and performance-based incentives to ensure fair and competitive wages. Regular market benchmarking will be conducted to adjust the bands according to industry trends.', 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/EaAFec6004tAg21g4i67rfgBBRqCm1yY7AZLLQyyaMtsEQ?e=wTMb4z', 'category': 'sharepoint', 'updated_at': 'No update date'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 14, 'name': 'Updating Your Tax Elections Forms', 'summary': ': This guide gives a step-by-step explanation of how to update your TD1 Personal Tax Credits Return form. Access the form from the CRA website and choose the correct version based on your province or territory of residence. Download and open the form in Adobe Reader, fill out the form by entering', 'url': './github/Updating Your Tax Elections Forms.txt', 'category': 'github', 'updated_at': 'No update date'}\n",
      "{'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 15, 'name': 'New Employee Onboarding Guide', 'summary': '\\nThis onboarding guide provides essential information to new employees on our company culture and values, key onboarding steps, tax elections and documents, benefits enrollment, and setting up their workspace.', 'url': './github/New Employee Onboarding guide.txt', 'category': 'github', 'updated_at': 'No update date'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)  # Verify the metadata includes 'name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk Import Passages\n",
    "\n",
    "Now that we have split each document into the chunk size of 800, we will now index data to elasticsearch using [ElasticsearchStore.from_documents](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html#langchain.vectorstores.elasticsearch.ElasticsearchStore.from_documents).\n",
    "\n",
    "We will use Cloud ID, Password and Index name values set in the `Create cloud deployment` step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 valid documents processed and indexed.\n"
     ]
    }
   ],
   "source": [
    "# Continue with the retriever process using split_docs (which are valid)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "vectorstore = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name=\"chatbot_index\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vectorstore.as_retriever(), llm)\n",
    "\n",
    "print(f\"{len(split_docs)} valid documents processed and indexed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering with MultiQuery Retriever\n",
    "\n",
    "Now that we have the passages stored in Elasticsearch, we can now ask a question to get the relevant passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def _combine_documents(\\n    docs, document_prompt=LLM_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\\n):\\n    doc_strings = [format_document(doc, document_prompt) for doc in docs]\\n    return document_separator.join(doc_strings)\\n\\n\\n_context = RunnableParallel(\\n    context=retriever | _combine_documents,\\n    question=RunnablePassthrough(),\\n)\\n\\nchain = _context | LLM_CONTEXT_PROMPT | llm\\n\\nans = chain.invoke(\"what is the nasa sales team?\")\\n\\nprint(\"---- Answer ----\")\\nprint(ans) '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.schema import format_document\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "LLM_CONTEXT_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Be as verbose and educational in your response as possible. \n",
    "    \n",
    "    context: {context}\n",
    "    Question: \"{question}\"\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "LLM_DOCUMENT_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "---\n",
    "SOURCE: {name}\n",
    "{page_content}\n",
    "---\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _combine_documents(docs, document_prompt=LLM_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    doc_strings = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        # Check if both 'name' and 'page_content' are present\n",
    "        if 'name' not in doc.metadata:\n",
    "            print(f\"Missing 'name' in document metadata: {doc.metadata}\")\n",
    "            continue  # Skip this document\n",
    "        \n",
    "        if not doc.page_content:\n",
    "            print(f\"Missing 'page_content' in document: {doc.metadata}\")\n",
    "            continue  # Skip this document\n",
    "        \n",
    "        # If both are present, format the document\n",
    "        doc_strings.append(format_document(doc, document_prompt))\n",
    "    \n",
    "    # Join all the formatted document strings\n",
    "    return document_separator.join(doc_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What are some methods for guaranteeing accurate tax deductions?', '2. How can I make sure that my tax deductions are correct?', '3. What steps should I take to ensure the accuracy of my tax deductions?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 'name' in document metadata: {'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 14}\n",
      "Missing 'name' in document metadata: {'source': 'C:\\\\Users\\\\KK\\\\Documents\\\\$$$IRONHACK\\\\7-Week-LangChain-RAG-Agents\\\\Day34\\\\lab-chatbot-with-multi-query-retriever\\\\temp.json', 'seq_num': 15}\n",
      "---- Answer ----\n",
      "To ensure correct tax deductions, it is important to update your tax elections forms, specifically the TD1 Personal Tax Credits Return form. This form can be accessed through the Canada Revenue Agency (CRA) website and should be filled out with accurate personal information and any applicable tax credits. It is important to carefully read the instructions for each section to ensure the correct amounts are claimed. Once completed, the form should be signed and submitted to your employer, who will use the information to calculate the correct amount of tax to be deducted from your pay. It is also important to regularly update the TD1 form whenever personal circumstances change, such as getting married or becoming eligible for a new tax credit. This will ensure that your tax deductions are accurate and avoid any discrepancies in your tax filings.\n"
     ]
    }
   ],
   "source": [
    "_context = RunnableParallel(\n",
    "    context=retriever | _combine_documents,\n",
    "    question=RunnablePassthrough(),\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "chain = _context | LLM_CONTEXT_PROMPT | llm\n",
    "\n",
    "ans = chain.invoke(\"how to ensure correct tax deduction?\")\n",
    "print(\"---- Answer ----\")\n",
    "print(ans)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate at least two new iteratioins of the previous cells - Be creative.** Did you master Multi-\n",
    "Query Retriever concepts through this lab?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
